{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d1 = pd.read_csv('201703-000000000000.csv', compression='gzip')\n",
    "\n",
    "def clean(line):\n",
    "    line = line.lower().replace(\"\\n\",\" \").replace(\"\\r\",\"\").replace(',',\"\").replace(\">\",\"> \")\n",
    "    return line\n",
    "\n",
    "def file_clean(f):\n",
    "    data = pd.read_csv(f, compression='gzip')\n",
    "    cleaned = []\n",
    "    for line in data['body']:\n",
    "        cleaned.append(clean(line))\n",
    "    data['cleaned'] = cleaned\n",
    "    data['cleaned'].to_csv('pq'+f[-7:])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d1[:100]\n",
    "d2.to_csv('sDirtyc.csv.', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'body', 'accepted_answer_id', 'answer_count',\n",
      "       'comment_count', 'community_owned_date', 'creation_date',\n",
      "       'favorite_count', 'last_activity_date', 'last_edit_date',\n",
      "       'last_editor_display_name', 'last_editor_user_id', 'owner_display_name',\n",
      "       'owner_user_id', 'post_type_id', 'score', 'tags', 'view_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(d2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p> it seems openstreetmap has changed their licensing scheme as a result lots of data were deleted as shown in the attached picture which is grafton nsw 2460 australia almost all streets are gone.</p>   <p> my question is: is there any way to download the old data somewhere by providing lat/lng's? (i understand that there could be some old archives for world or some countries but that doesn't work for me because at the moment my application is not capable to process those massive data files)</p>   <p> if there's no way to download the old data is there any other good free map data (not images) available?</p>   <p> also i've noticed that there're 4 options at the top right corner the other three except standard seem to be showing all streets. they are (at least mapquest) based on osm data but not the one we get from the \"export\" section of openstreetmap.org is that correct? </p>   <p> edit: oops as a new user i cannot post images.. the below link may work (or may not):</p>   <p> <a href=\"http://i.stack.imgur.com/ieixt.png\" rel=\"nofollow\"> http://i.stack.imgur.com/ieixt.png</a> </p>   <p> (it's just 2 snapshots of grafton nsw 2460 australia one of standard one of mapquest open)</p> \n"
     ]
    }
   ],
   "source": [
    "# print(d1.iloc[0])\n",
    "print(clean(d1.iloc[0]['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Data Clean\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|      id|               title|                body|                tags|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|11823544|How could I downl...|<p>It seems opens...|       openstreetmap|\n",
      "|33915105|Get All Records W...|<p>I have a blog ...|           php|mysql|\n",
      "|14039235|No effect on noti...|<p>I am using a l...|android-notificat...|\n",
      "|27416240|How to find the p...|<p>I have a prope...|c#|msbuild|msbuil...|\n",
      "|16236899|Is there an equiv...|<p>I've been usin...|python|python-2.7...|\n",
      "|26247120|Python - Selectin...|<p>I have a form ...|python|csv|python...|\n",
      "| 7972886|jaxb annotations ...|<p>For my sins, I...|                jaxb|\n",
      "|27909083|ConnectivityManag...|<p>I have a quest...|android|android-n...|\n",
      "|35480928|ALSA unexpected r...|<p>The ALSA lib c...|      linux|gcc|alsa|\n",
      "| 9436233|Why is System.Typ...|<p>I have a littl...|       c#|reflection|\n",
      "|22568583|Can ASP.NET Web A...|<p>I have the fol...|json|asp.net-web-...|\n",
      "|14298363|How to dynamic ad...|<p>I am using <co...|wpf|animation|3d|...|\n",
      "|28560545|Symfony2 Multiple...|<p>I am learning ...|symfony|file-uplo...|\n",
      "|10504156|EF Code First dep...|<p>I have an MVC ...|asp.net-mvc|entit...|\n",
      "|  935354|Reporting Service...|<p>I'm looking fo...|sql|stored-proced...|\n",
      "|20510787|Search for Mentio...|<p>I'm looking to...|             twitter|\n",
      "|29248735|Getting Error whi...|<p>5, getting err...|mysql|mysql-workb...|\n",
      "|17552646|Do I need to regi...|<p>I've tried set...|android|google-pl...|\n",
      "|14370698|Restricted access...|<p>I started play...|actionscript-3|de...|\n",
      "|33642798|How can I check-i...|<p>I have a nativ...|    tfsbuild|tfs2015|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dirtyData = spark.read.format(\"csv.gz\").csv(\"sDirtyc.csv.gz\", header=True, multiLine=True, escape='\"')\n",
    "dirtyData.select('id', 'title', 'body','tags').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        cleaned_body|\n",
      "+--------------------+\n",
      "| <p> it seems ope...|\n",
      "| <p> i have a blo...|\n",
      "| <p> i am using a...|\n",
      "| <p> i have a pro...|\n",
      "| <p> i've been us...|\n",
      "| <p> i have a for...|\n",
      "| <p> for my sins ...|\n",
      "| <p> i have a que...|\n",
      "| <p> the alsa lib...|\n",
      "| <p> i have a lit...|\n",
      "| <p> i have the f...|\n",
      "| <p> i am using  ...|\n",
      "| <p> i am learnin...|\n",
      "| <p> i have an mv...|\n",
      "| <p> i'm looking ...|\n",
      "| <p> i'm looking ...|\n",
      "| <p> 5 getting er...|\n",
      "| <p> i've tried s...|\n",
      "| <p> i started pl...|\n",
      "| <p> i have a nat...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def clean(line):\n",
    "    line = line.lower().replace(\"\\n\",\" \").replace(\"\\r\",\"\").replace(',',\"\").replace(\">\",\"> \").replace(\"<\", \" <\")\n",
    "    return line\n",
    "clean_udf = udf(lambda r: clean(r), StringType())\n",
    "\n",
    "dirtyData = spark.read.csv(\"sDirtyc.csv.gz\", header=True, multiLine=True, escape='\"')\n",
    "# dirtyData.select('id', 'title', 'body','tags').show()\n",
    "dirtyData = dirtyData.withColumn('cleaned_body', clean_udf(dirtyData['body']))\n",
    "dirtyData.select('cleaned_body').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               words|\n",
      "+--------------------+\n",
      "|[, <p>, it, seems...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, i, am, us...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, i've, bee...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, for, my, ...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, the, alsa...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, i, am, us...|\n",
      "|[, <p>, i, am, le...|\n",
      "|[, <p>, i, have, ...|\n",
      "|[, <p>, i'm, look...|\n",
      "|[, <p>, i'm, look...|\n",
      "|[, <p>, 5, gettin...|\n",
      "|[, <p>, i've, tri...|\n",
      "|[, <p>, i, starte...|\n",
      "|[, <p>, i, have, ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IDF, IDFModel, Tokenizer\n",
    "tk = Tokenizer(inputCol='cleaned_body', outputCol='words')\n",
    "words = tk.transform(dirtyData)\n",
    "words.select('words').show()\n",
    "# dirtyData.select('words').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
